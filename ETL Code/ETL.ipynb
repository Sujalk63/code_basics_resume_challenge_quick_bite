{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3504ae",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc18cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import os # for handling files\n",
    "import pandas as pd # for data cleaning \n",
    "\n",
    "from dotenv import load_dotenv #\n",
    "load_dotenv(override=True) \n",
    "\n",
    "\n",
    "import sqlalchemy as sal # for connecting to sql database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a9290",
   "metadata": {},
   "source": [
    "### Cleaning and Filtering data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1be44691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_customer: Original rows = 107776, After cleaning = 107776\n",
      "dim_delivery_partner: Original rows = 15000, After cleaning = 15000\n",
      "dim_menu_item: Original rows = 342671, After cleaning = 342671\n",
      "dim_restaurant: Original rows = 19995, After cleaning = 19995\n",
      "fact_delivery_performance: Original rows = 149166, After cleaning = 149166\n",
      "fact_orders: Original rows = 149166, After cleaning = 149166\n",
      "fact_order_items: Original rows = 342994, After cleaning = 342994\n",
      "fact_ratings: Original rows = 68842, After cleaning = 68825\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.getenv(\"FOLDER_PATH\")\n",
    "\n",
    "cleaned_tables = {}\n",
    "\n",
    "# Loop through all CSV files in folder and remove duplicates or blanks rows(IF EXISTS!!)\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        table_name = file.replace(\".csv\", \"\")\n",
    "        df = pd.read_csv(os.path.join(folder_path, file))\n",
    "        original_rows = len(df)\n",
    "        \n",
    "        # Remove rows where all columns are NaN, if exists\n",
    "        df = df.dropna(how=\"all\")\n",
    "        \n",
    "        # Remove row duplicates, if exists\n",
    "        df_cleaned = df.drop_duplicates()\n",
    "        \n",
    "        print(f\"{table_name}: Original rows = {original_rows}, After cleaning = {len(df_cleaned)}\")\n",
    "        \n",
    "        # Save cleaned DataFrame in dictionary\n",
    "        cleaned_tables[table_name] = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33a0ce6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>delivery_partner_id</th>\n",
       "      <th>order_timestamp</th>\n",
       "      <th>subtotal_amount</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>is_cod</th>\n",
       "      <th>is_cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD202501023439</td>\n",
       "      <td>CUST181110</td>\n",
       "      <td>REST08622</td>\n",
       "      <td>DP05541</td>\n",
       "      <td>2025-01-01 12:00:00</td>\n",
       "      <td>471.62</td>\n",
       "      <td>35.44</td>\n",
       "      <td>30.56</td>\n",
       "      <td>466.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD202501012051</td>\n",
       "      <td>CUST025572</td>\n",
       "      <td>REST02383</td>\n",
       "      <td>DP08091</td>\n",
       "      <td>2025-01-01 12:00:00</td>\n",
       "      <td>255.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.45</td>\n",
       "      <td>283.13</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD202501019281</td>\n",
       "      <td>CUST179306</td>\n",
       "      <td>REST14069</td>\n",
       "      <td>DP02021</td>\n",
       "      <td>2025-01-01 12:00:00</td>\n",
       "      <td>428.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.23</td>\n",
       "      <td>454.61</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD202501000124</td>\n",
       "      <td>CUST191820</td>\n",
       "      <td>REST19745</td>\n",
       "      <td>DP13859</td>\n",
       "      <td>2025-01-01 12:00:00</td>\n",
       "      <td>260.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.75</td>\n",
       "      <td>293.56</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD202501006518</td>\n",
       "      <td>CUST033760</td>\n",
       "      <td>REST12962</td>\n",
       "      <td>DP09615</td>\n",
       "      <td>2025-01-01 12:00:00</td>\n",
       "      <td>280.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.57</td>\n",
       "      <td>305.90</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORD202501018255</td>\n",
       "      <td>CUST011850</td>\n",
       "      <td>REST01307</td>\n",
       "      <td>DP14063</td>\n",
       "      <td>2025-01-01 12:01:00</td>\n",
       "      <td>310.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.05</td>\n",
       "      <td>345.99</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORD202501004299</td>\n",
       "      <td>CUST107475</td>\n",
       "      <td>REST12542</td>\n",
       "      <td>DP07728</td>\n",
       "      <td>2025-01-01 12:02:00</td>\n",
       "      <td>206.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.62</td>\n",
       "      <td>237.03</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORD202501018036</td>\n",
       "      <td>CUST093042</td>\n",
       "      <td>REST13907</td>\n",
       "      <td>DP01276</td>\n",
       "      <td>2025-01-01 12:03:00</td>\n",
       "      <td>300.30</td>\n",
       "      <td>48.31</td>\n",
       "      <td>31.41</td>\n",
       "      <td>283.40</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORD202501009329</td>\n",
       "      <td>CUST104825</td>\n",
       "      <td>REST10267</td>\n",
       "      <td>DP03078</td>\n",
       "      <td>2025-01-01 12:04:00</td>\n",
       "      <td>371.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.35</td>\n",
       "      <td>405.95</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORD202501007498</td>\n",
       "      <td>CUST135654</td>\n",
       "      <td>REST05434</td>\n",
       "      <td>DP11625</td>\n",
       "      <td>2025-01-01 12:06:00</td>\n",
       "      <td>306.23</td>\n",
       "      <td>33.38</td>\n",
       "      <td>20.70</td>\n",
       "      <td>293.55</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id customer_id restaurant_id delivery_partner_id  \\\n",
       "0  ORD202501023439  CUST181110     REST08622             DP05541   \n",
       "1  ORD202501012051  CUST025572     REST02383             DP08091   \n",
       "2  ORD202501019281  CUST179306     REST14069             DP02021   \n",
       "3  ORD202501000124  CUST191820     REST19745             DP13859   \n",
       "4  ORD202501006518  CUST033760     REST12962             DP09615   \n",
       "5  ORD202501018255  CUST011850     REST01307             DP14063   \n",
       "6  ORD202501004299  CUST107475     REST12542             DP07728   \n",
       "7  ORD202501018036  CUST093042     REST13907             DP01276   \n",
       "8  ORD202501009329  CUST104825     REST10267             DP03078   \n",
       "9  ORD202501007498  CUST135654     REST05434             DP11625   \n",
       "\n",
       "       order_timestamp  subtotal_amount  discount_amount  delivery_fee  \\\n",
       "0  2025-01-01 12:00:00           471.62            35.44         30.56   \n",
       "1  2025-01-01 12:00:00           255.68             0.00         27.45   \n",
       "2  2025-01-01 12:00:00           428.38             0.00         26.23   \n",
       "3  2025-01-01 12:00:00           260.81             0.00         32.75   \n",
       "4  2025-01-01 12:00:00           280.33             0.00         25.57   \n",
       "5  2025-01-01 12:01:00           310.95             0.00         35.05   \n",
       "6  2025-01-01 12:02:00           206.41             0.00         30.62   \n",
       "7  2025-01-01 12:03:00           300.30            48.31         31.41   \n",
       "8  2025-01-01 12:04:00           371.60             0.00         34.35   \n",
       "9  2025-01-01 12:06:00           306.23            33.38         20.70   \n",
       "\n",
       "   total_amount is_cod is_cancelled  \n",
       "0        466.74      N            N  \n",
       "1        283.13      Y            N  \n",
       "2        454.61      N            N  \n",
       "3        293.56      N            N  \n",
       "4        305.90      N            N  \n",
       "5        345.99      Y            N  \n",
       "6        237.03      Y            N  \n",
       "7        283.40      N            N  \n",
       "8        405.95      N            N  \n",
       "9        293.55      N            N  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tables[\"fact_orders\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382802cc",
   "metadata": {},
   "source": [
    "### Connecting to MS SQL server and creating Database and Schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9ba9793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'quick_bite_database' already exists.\n",
      "Schema 'quick_bite_schema' already exists.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "load_dotenv(override=True) \n",
    "\n",
    "engine_url = os.getenv(\"DB_ENGINE_URL\")  # master DB URL\n",
    "schema_name = \"quick_bite_schema\"\n",
    "database_name = \"quick_bite_database\"\n",
    "\n",
    "# Connect to master to create database if not exists\n",
    "engine_master = create_engine(engine_url)\n",
    "\n",
    "with engine_master.connect().execution_options(isolation_level=\"AUTOCOMMIT\") as conn:\n",
    "    try:\n",
    "        # Ensure database exists\n",
    "        result = conn.execute(text(f\"SELECT * FROM sys.databases WHERE name='{database_name}'\"))\n",
    "        if result.fetchone(): \n",
    "            print(f\"Database '{database_name}' already exists.\")\n",
    "        else:\n",
    "            conn.execute(text(f\"CREATE DATABASE {database_name};\"))\n",
    "            print(f\"Database '{database_name}' created successfully.\")\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Failed to create database '{database_name}': {e}\")\n",
    "\n",
    "# Connect to the actual database \"quick_bite_database\"\n",
    "engine_db = create_engine(\n",
    "    f\"mssql+pyodbc://localhost\\\\SQLEXPRESS/{database_name}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\"\n",
    ")\n",
    "\n",
    "# --- 3. Ensure schema exists ---\n",
    "with engine_db.connect().execution_options(isolation_level=\"AUTOCOMMIT\") as conn:\n",
    "    try:\n",
    "        result = conn.execute(text(f\"SELECT * FROM sys.schemas WHERE name='{schema_name}'\"))\n",
    "        if result.fetchone():\n",
    "            print(f\"Schema '{schema_name}' already exists.\")\n",
    "        else:\n",
    "            conn.execute(text(f\"EXEC('CREATE SCHEMA {schema_name}')\"))\n",
    "            print(f\"Schema '{schema_name}' created successfully.\")\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Failed to create schema '{schema_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01201b41",
   "metadata": {},
   "source": [
    "### Load data to SQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_customer pushed to SQL Server schema 'quick_bite_schema'.\n",
      "dim_delivery_partner pushed to SQL Server schema 'quick_bite_schema'.\n",
      "dim_menu_item pushed to SQL Server schema 'quick_bite_schema'.\n",
      "dim_restaurant pushed to SQL Server schema 'quick_bite_schema'.\n",
      "fact_delivery_performance pushed to SQL Server schema 'quick_bite_schema'.\n",
      "fact_orders pushed to SQL Server schema 'quick_bite_schema'.\n",
      "fact_order_items pushed to SQL Server schema 'quick_bite_schema'.\n",
      "fact_ratings pushed to SQL Server schema 'quick_bite_schema'.\n",
      "Table 'dim_customer' cleaned and replaced in SQL (NaNs & exact duplicates removed).\n",
      "Table 'dim_delivery_partner' cleaned and replaced in SQL (NaNs & exact duplicates removed).\n",
      "Table 'dim_menu_item' cleaned and replaced in SQL (NaNs & exact duplicates removed).\n",
      "Table 'dim_restaurant' cleaned and replaced in SQL (NaNs & exact duplicates removed).\n",
      "Table 'fact_delivery_performance' cleaned and replaced in SQL (NaNs & exact duplicates removed).\n",
      "Table 'fact_orders' cleaned and replaced in SQL (NaNs & exact duplicates removed).\n",
      "Table 'fact_order_items' cleaned and replaced in SQL (NaNs & exact duplicates removed).\n",
      "Table 'fact_ratings' cleaned and replaced in SQL (NaNs & exact duplicates removed).\n",
      "ETL Process Completed Successfully!\n"
     ]
    }
   ],
   "source": [
    "for table_name, df in cleaned_tables.items():\n",
    "    df.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine_db,\n",
    "        schema=schema_name,\n",
    "        if_exists='append',  # Append new data if table exists\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"{table_name} pushed to SQL Server schema '{schema_name}'.\")\n",
    "\n",
    "print(\"ETL Process Completed Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fa7db",
   "metadata": {},
   "source": [
    "### Optional step, if by mistakenly user ran the script multiple times and then wants to clear the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96831444",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in cleaned_tables.keys():\n",
    "    # Fetch the table back from SQL\n",
    "    df_db = pd.read_sql_table(table_name, con=engine_db, schema=schema_name)\n",
    "    \n",
    "    # Remove rows where all columns are NaN\n",
    "    df_db_cleaned = df_db.dropna(how=\"all\")\n",
    "    \n",
    "    # Remove exact duplicate rows (all columns identical)\n",
    "    df_db_cleaned = df_db_cleaned.drop_duplicates()\n",
    "    \n",
    "    # Replace the table in SQL with cleaned data\n",
    "    df_db_cleaned.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine_db,\n",
    "        schema=schema_name,\n",
    "        if_exists='replace',  # Replace the existing table\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Table '{table_name}' cleaned and replaced in SQL (NaNs & exact duplicates removed).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
